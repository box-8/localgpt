# Llama Server 

# DOCS 
https://llama-cpp-python.readthedocs.io/en/latest/server/
 
# INSTALL
https://www.youtube.com/watch?v=1dkmKt1PDoI
 
# windows c++ compiler
https://github.com/skeeto/w64devkit/releases

# llama source files
https://github.com/ggerganov/llama.cpp
# Python install packages

pip install requirements 
llama-cpp-python
llama-cpp-python[server]

# LAUNCH
python -m llama_cpp.server --model models/mistral-7b-instruct-v0.2.Q4_K_S.gguf --port 1234